{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "Text Summary - BBC News.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1BrkuW6GKUmi5oXGqa7I32410gFDh8xXN",
      "authorship_tag": "ABX9TyPG7lytJ7tF67EzGgXW7rAW",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ranjith13119/Seq2Seq---Text-Summarization/blob/main/Text_Summary_BBC_News.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-COMMQYS5LLN"
      },
      "source": [
        "# import os\n",
        "# os.environ['KAGGLE_CONFIG_DIR'] = \"/content/drive/MyDrive/Kaggle\"\n",
        "# %cd /content/drive/MyDrive/NLP/Text Summary\n",
        "# !kaggle datasets download -d sunnysai12345/news-summary\n",
        "# #unzipping the zip files and deleting the zip files\n",
        "# !unzip \\*.zip  && rm *.zipy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VINLyJfy5ssE"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIELnTk45xaK"
      },
      "source": [
        "summary = pd.read_csv(\"/content/drive/MyDrive/NLP/Text Summary/news_summary.csv\", encoding='iso-8859-1')\n",
        "summary_raw = pd.read_csv(\"/content/drive/MyDrive/NLP/Text Summary/news_summary_more.csv\", encoding='iso-8859-1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "mpbRFL2n6R37",
        "outputId": "ef79da3a-7737-473d-f33f-51c341a00344"
      },
      "source": [
        "summary_raw.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>headlines</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>upGrad learner switches to career in ML &amp; Al w...</td>\n",
              "      <td>Saurav Kant, an alumnus of upGrad and IIIT-B's...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Delhi techie wins free food from Swiggy for on...</td>\n",
              "      <td>Kunal Shah's credit card bill payment platform...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>New Zealand end Rohit Sharma-led India's 12-ma...</td>\n",
              "      <td>New Zealand defeated India by 8 wickets in the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Aegon life iTerm insurance plan helps customer...</td>\n",
              "      <td>With Aegon Life iTerm Insurance plan, customer...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Have known Hirani for yrs, what if MeToo claim...</td>\n",
              "      <td>Speaking about the sexual harassment allegatio...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           headlines                                               text\n",
              "0  upGrad learner switches to career in ML & Al w...  Saurav Kant, an alumnus of upGrad and IIIT-B's...\n",
              "1  Delhi techie wins free food from Swiggy for on...  Kunal Shah's credit card bill payment platform...\n",
              "2  New Zealand end Rohit Sharma-led India's 12-ma...  New Zealand defeated India by 8 wickets in the...\n",
              "3  Aegon life iTerm insurance plan helps customer...  With Aegon Life iTerm Insurance plan, customer...\n",
              "4  Have known Hirani for yrs, what if MeToo claim...  Speaking about the sexual harassment allegatio..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "id": "YEVbfGdw6qzr",
        "outputId": "692f930c-acf2-4952-b24f-e7eabfe197f8"
      },
      "source": [
        "summary.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>author</th>\n",
              "      <th>date</th>\n",
              "      <th>headlines</th>\n",
              "      <th>read_more</th>\n",
              "      <th>text</th>\n",
              "      <th>ctext</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Chhavi Tyagi</td>\n",
              "      <td>03 Aug 2017,Thursday</td>\n",
              "      <td>Daman &amp; Diu revokes mandatory Rakshabandhan in...</td>\n",
              "      <td>http://www.hindustantimes.com/india-news/raksh...</td>\n",
              "      <td>The Administration of Union Territory Daman an...</td>\n",
              "      <td>The Daman and Diu administration on Wednesday ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Daisy Mowke</td>\n",
              "      <td>03 Aug 2017,Thursday</td>\n",
              "      <td>Malaika slams user who trolled her for 'divorc...</td>\n",
              "      <td>http://www.hindustantimes.com/bollywood/malaik...</td>\n",
              "      <td>Malaika Arora slammed an Instagram user who tr...</td>\n",
              "      <td>From her special numbers to TV?appearances, Bo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Arshiya Chopra</td>\n",
              "      <td>03 Aug 2017,Thursday</td>\n",
              "      <td>'Virgin' now corrected to 'Unmarried' in IGIMS...</td>\n",
              "      <td>http://www.hindustantimes.com/patna/bihar-igim...</td>\n",
              "      <td>The Indira Gandhi Institute of Medical Science...</td>\n",
              "      <td>The Indira Gandhi Institute of Medical Science...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sumedha Sehra</td>\n",
              "      <td>03 Aug 2017,Thursday</td>\n",
              "      <td>Aaj aapne pakad liya: LeT man Dujana before be...</td>\n",
              "      <td>http://indiatoday.intoday.in/story/abu-dujana-...</td>\n",
              "      <td>Lashkar-e-Taiba's Kashmir commander Abu Dujana...</td>\n",
              "      <td>Lashkar-e-Taiba's Kashmir commander Abu Dujana...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Aarushi Maheshwari</td>\n",
              "      <td>03 Aug 2017,Thursday</td>\n",
              "      <td>Hotel staff to get training to spot signs of s...</td>\n",
              "      <td>http://indiatoday.intoday.in/story/sex-traffic...</td>\n",
              "      <td>Hotels in Maharashtra will train their staff t...</td>\n",
              "      <td>Hotels in Mumbai and other Indian cities are t...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               author  ...                                              ctext\n",
              "0        Chhavi Tyagi  ...  The Daman and Diu administration on Wednesday ...\n",
              "1         Daisy Mowke  ...  From her special numbers to TV?appearances, Bo...\n",
              "2      Arshiya Chopra  ...  The Indira Gandhi Institute of Medical Science...\n",
              "3       Sumedha Sehra  ...  Lashkar-e-Taiba's Kashmir commander Abu Dujana...\n",
              "4  Aarushi Maheshwari  ...  Hotels in Mumbai and other Indian cities are t...\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVPHSg3n7F4V"
      },
      "source": [
        "pre1 =  summary_raw.iloc[:,0:2].copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHT95G3K7IFl"
      },
      "source": [
        "pre2 = summary.iloc[:,0:6].copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihro8Lz77fCS"
      },
      "source": [
        "pre2['text'] = pre2['author'].str.cat(pre2['date'].str.cat(pre2['read_more'].str.cat(pre2['text'].str.cat(pre2['ctext'], sep = \" \"), sep =\" \"),sep= \" \"), sep = \" \")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4NteRQa7mfc"
      },
      "source": [
        "data = pd.DataFrame()\n",
        "data['text'] = pd.concat([pre1['text'], pre2['text']], ignore_index=True)\n",
        "data['summary'] = pd.concat([pre1['headlines'],pre2['headlines']],ignore_index = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "zQVOgmyi7uAK",
        "outputId": "8517f8fc-5dc5-4ae3-e508-01ac3b5f65b8"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Saurav Kant, an alumnus of upGrad and IIIT-B's...</td>\n",
              "      <td>upGrad learner switches to career in ML &amp; Al w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Kunal Shah's credit card bill payment platform...</td>\n",
              "      <td>Delhi techie wins free food from Swiggy for on...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>New Zealand defeated India by 8 wickets in the...</td>\n",
              "      <td>New Zealand end Rohit Sharma-led India's 12-ma...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>With Aegon Life iTerm Insurance plan, customer...</td>\n",
              "      <td>Aegon life iTerm insurance plan helps customer...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Speaking about the sexual harassment allegatio...</td>\n",
              "      <td>Have known Hirani for yrs, what if MeToo claim...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text                                            summary\n",
              "0  Saurav Kant, an alumnus of upGrad and IIIT-B's...  upGrad learner switches to career in ML & Al w...\n",
              "1  Kunal Shah's credit card bill payment platform...  Delhi techie wins free food from Swiggy for on...\n",
              "2  New Zealand defeated India by 8 wickets in the...  New Zealand end Rohit Sharma-led India's 12-ma...\n",
              "3  With Aegon Life iTerm Insurance plan, customer...  Aegon life iTerm insurance plan helps customer...\n",
              "4  Speaking about the sexual harassment allegatio...  Have known Hirani for yrs, what if MeToo claim..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcyW2fLR8GDT"
      },
      "source": [
        "import re\n",
        "\n",
        "#Removes non-alphabetic characters:\n",
        "def text_strip(column):\n",
        "    for row in column:\n",
        "\n",
        "        row=re.sub(\"(\\\\t)\", ' ', str(row)).lower() #remove escape charecters\n",
        "        row=re.sub(\"(\\\\r)\", ' ', str(row)).lower() #remove carriage return character\n",
        "        row=re.sub(\"(\\\\n)\", ' ', str(row)).lower() #remove new line character\n",
        "        \n",
        "        row=re.sub(\"(__+)\", ' ', str(row)).lower()   #remove _ if it occors more than one time consecutively\n",
        "        row=re.sub(\"(--+)\", ' ', str(row)).lower()   #remove - if it occors more than one time consecutively\n",
        "        row=re.sub(\"(~~+)\", ' ', str(row)).lower()   #remove ~ if it occors more than one time consecutively\n",
        "        row=re.sub(\"(\\+\\++)\", ' ', str(row)).lower()   #remove + if it occors more than one time consecutively\n",
        "        row=re.sub(\"(\\.\\.+)\", ' ', str(row)).lower()   #remove . if it occors more than one time consecutively\n",
        "        \n",
        "        row=re.sub(r\"[<>()|&©ø\\[\\]\\'\\\",;?~*!]\", ' ', str(row)).lower() #remove <>()|&©ø\"',;?~*!\n",
        "        \n",
        "        row=re.sub(\"(mailto:)\", ' ', str(row)).lower() #remove mailto:\n",
        "        row=re.sub(r\"(\\\\x9\\d)\", ' ', str(row)).lower() #remove \\x9* in text\n",
        "        row=re.sub(\"([iI][nN][cC]\\d+)\", 'INC_NUM', str(row)).lower() #replace INC nums to INC_NUM\n",
        "        row=re.sub(\"([cC][mM]\\d+)|([cC][hH][gG]\\d+)\", 'CM_NUM', str(row)).lower() #replace CM# and CHG# to CM_NUM\n",
        "        \n",
        "        \n",
        "        row=re.sub(\"(\\.\\s+)\", ' ', str(row)).lower() #remove full stop at end of words(not between)\n",
        "        row=re.sub(\"(\\-\\s+)\", ' ', str(row)).lower() #remove - at end of words(not between)\n",
        "        row=re.sub(\"(\\:\\s+)\", ' ', str(row)).lower() #remove : at end of words(not between)\n",
        "        \n",
        "        row=re.sub(\"(\\s+.\\s+)\", ' ', str(row)).lower() #remove any single charecters hanging between 2 spaces\n",
        "        \n",
        "        #Replace any url as such https://abc.xyz.net/browse/sdf-5327 ====> abc.xyz.net\n",
        "        try:\n",
        "            url = re.search(r'((https*:\\/*)([^\\/\\s]+))(.[^\\s]+)', str(row))\n",
        "            repl_url = url.group(3)\n",
        "            row = re.sub(r'((https*:\\/*)([^\\/\\s]+))(.[^\\s]+)',repl_url, str(row))\n",
        "        except:\n",
        "            pass #there might be emails with no url in them\n",
        "        \n",
        "        row = re.sub(\"(\\s+)\",' ',str(row)).lower() #remove multiple spaces\n",
        "\n",
        "        #Should always be last\n",
        "        row=re.sub(\"(\\s+.\\s+)\", ' ', str(row)).lower() #remove any single charecters hanging between 2 spaces\n",
        "\n",
        "        yield row"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uu8OsHs58jt4"
      },
      "source": [
        "brief_cleaning1 = text_strip(data['text'])\n",
        "brief_cleaning2 = text_strip(data['summary'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWAVGZcP8m9g",
        "outputId": "859244ea-24b0-4d07-93c6-cfa2cc28e2b3"
      },
      "source": [
        "from time import time\n",
        "import spacy\n",
        "nlp = spacy.load('en', disable=['ner', 'parser']) # disabling Named Entity Recognition for speed\n",
        "\n",
        "#Taking advantage of spaCy .pipe() method to speed-up the cleaning process:\n",
        "#If data loss seems to be happening(i.e len(text) = 50 instead of 75 etc etc) in this cell , decrease the batch_size parametre \n",
        "\n",
        "t = time()\n",
        "\n",
        "#Batch the data points into 5000 and run on all cores for faster preprocessing\n",
        "text = [str(doc) for doc in nlp.pipe(brief_cleaning1, batch_size=5000, n_threads=-1)]\n",
        "\n",
        "#Takes 7-8 mins\n",
        "print('Time to clean up everything: {} mins'.format(round((time() - t) / 60, 2)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time to clean up everything: 4.98 mins\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wn7hZDZ8wpJG",
        "outputId": "bc487880-9391-41fc-e312-9a8111f5140e"
      },
      "source": [
        "t = time()\n",
        "\n",
        "#Batch the data points into 5000 and run on all cores for faster preprocessing\n",
        "summary = ['_START_ '+ str(doc) + ' _END_' for doc in nlp.pipe(brief_cleaning2, batch_size=5000, n_threads=-1)]\n",
        "\n",
        "#Takes 7-8 mins\n",
        "print('Time to clean up everything: {} mins'.format(round((time() - t) / 60, 2)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time to clean up everything: 0.93 mins\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xP31Gnvjw6V8"
      },
      "source": [
        "data['cleaned_text'] = pd.Series(text)\n",
        "data['cleaned_summary'] = pd.Series(summary)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYPT0XZ3xMj5"
      },
      "source": [
        "text_count = []\n",
        "summary_count = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbEhy6WQxR-w"
      },
      "source": [
        "for sent in data['cleaned_text']:\n",
        "    text_count.append(len(sent.split()))\n",
        "for sent in data['cleaned_summary']:\n",
        "    summary_count.append(len(sent.split()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gF7wwhHQxTN9"
      },
      "source": [
        "graph_df= pd.DataFrame()\n",
        "graph_df['text']=text_count\n",
        "graph_df['summary']=summary_count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "EHV-R-EYxWAg",
        "outputId": "f4f67342-06df-41d7-8083-1eb308c1182a"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "graph_df.hist(bins = 5)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ub9vwbT_xaoV",
        "outputId": "688e0ad7-3483-481e-dba9-1c1228f489ff"
      },
      "source": [
        "#Check how much % of summary have 0-15 words\n",
        "cnt=0\n",
        "for i in data['cleaned_summary']:\n",
        "    if(len(i.split())<=15):\n",
        "        cnt=cnt+1\n",
        "print(cnt/len(data['cleaned_summary']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9978234465335472\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cf9bZ4koxdCd",
        "outputId": "1b98386a-3bcd-4114-b848-996fe041c874"
      },
      "source": [
        "#Check how much % of text have 0-100 words\n",
        "cnt=0\n",
        "for i in data['cleaned_text']:\n",
        "    if(len(i.split())<=100):\n",
        "        cnt=cnt+1\n",
        "print(cnt/len(data['cleaned_text']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9578389933440218\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_yMXSTZxhgz"
      },
      "source": [
        "#Model to summarize the text between 0-15 words for Summary and 0-100 words for Text\n",
        "max_text_len=100\n",
        "max_summary_len=15"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5VYja5txmfV"
      },
      "source": [
        "#Select the Summaries and Text between max len defined above\n",
        "cleaned_text =np.array(data['cleaned_text'])\n",
        "cleaned_summary=np.array(data['cleaned_summary'])\n",
        "\n",
        "short_text=[]\n",
        "short_summary=[]\n",
        "\n",
        "for i in range(len(cleaned_text)):\n",
        "    if(len(cleaned_summary[i].split())<=max_summary_len and len(cleaned_text[i].split())<=max_text_len):\n",
        "        short_text.append(cleaned_text[i])\n",
        "        short_summary.append(cleaned_summary[i])\n",
        "        \n",
        "post_pre=pd.DataFrame({'text':short_text,'summary':short_summary})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "19EvLYQYxs84",
        "outputId": "8d08cd20-e520-4e97-faf6-f63d271b3346"
      },
      "source": [
        "post_pre.head(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>saurav kant an alumnus of upgrad and iiit-b pg...</td>\n",
              "      <td>_START_ upgrad learner switches to career in m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>kunal shah credit card bill payment platform c...</td>\n",
              "      <td>_START_ delhi techie wins free food from swigg...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text                                            summary\n",
              "0  saurav kant an alumnus of upgrad and iiit-b pg...  _START_ upgrad learner switches to career in m...\n",
              "1  kunal shah credit card bill payment platform c...  _START_ delhi techie wins free food from swigg..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMUiCpRkx0se"
      },
      "source": [
        "#Add sostok and eostok at \n",
        "post_pre['summary'] = post_pre['summary'].apply(lambda x : 'sostok '+ x + ' eostok')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q09YKe93x8JU"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_tr,x_val,y_tr,y_val=train_test_split(np.array(post_pre['text']),np.array(post_pre['summary']),test_size=0.1,random_state=0,shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84gxAYFOyAQy"
      },
      "source": [
        "#Lets tokenize the text to get the vocab count , you can use Spacy here also\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer \n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "#prepare a tokenizer for reviews on training data\n",
        "x_tokenizer = Tokenizer() \n",
        "x_tokenizer.fit_on_texts(list(x_tr))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WyNEYFfcyalj",
        "outputId": "4c9bdb27-aa9f-420b-a6e6-63bc0a540ff4"
      },
      "source": [
        "thresh=4\n",
        "\n",
        "cnt=0\n",
        "tot_cnt=0\n",
        "freq=0\n",
        "tot_freq=0\n",
        "\n",
        "for key,value in x_tokenizer.word_counts.items():\n",
        "    tot_cnt=tot_cnt+1\n",
        "    tot_freq=tot_freq+value\n",
        "    if(value<thresh):\n",
        "        cnt=cnt+1\n",
        "        freq=freq+value\n",
        "    \n",
        "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
        "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "% of rare words in vocabulary: 57.91270391131826\n",
            "Total Coverage of rare words: 1.3404923996005096\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEhBUk0pyhJB",
        "outputId": "c4ac63c3-84fd-4ea4-af35-563b9499cb77"
      },
      "source": [
        "#prepare a tokenizer for reviews on training data\n",
        "x_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \n",
        "x_tokenizer.fit_on_texts(list(x_tr))\n",
        "\n",
        "#convert text sequences into integer sequences (i.e one-hot encodeing all the words)\n",
        "x_tr_seq    =   x_tokenizer.texts_to_sequences(x_tr) \n",
        "x_val_seq   =   x_tokenizer.texts_to_sequences(x_val)\n",
        "\n",
        "#padding zero upto maximum length\n",
        "x_tr    =   pad_sequences(x_tr_seq,  maxlen=max_text_len, padding='post')\n",
        "x_val   =   pad_sequences(x_val_seq, maxlen=max_text_len, padding='post')\n",
        "\n",
        "#size of vocabulary ( +1 for padding token)\n",
        "x_voc   =  x_tokenizer.num_words + 1\n",
        "\n",
        "print(\"Size of vocabulary in X = {}\".format(x_voc))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of vocabulary in X = 33412\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPiMJHfWysWS"
      },
      "source": [
        "tot_cnt gives the size of vocabulary (which means every unique words in the text)\n",
        "\n",
        "cnt gives me the no. of rare words whose count falls below threshold\n",
        "\n",
        "tot_cnt - cnt gives me the top most common words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nakuMBWyoqL"
      },
      "source": [
        "#prepare a tokenizer for reviews on training data\n",
        "y_tokenizer = Tokenizer()   \n",
        "y_tokenizer.fit_on_texts(list(y_tr))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bwri7payzGM",
        "outputId": "2f596b58-b662-4a4a-db1c-651450577502"
      },
      "source": [
        "thresh=6\n",
        "cnt=0\n",
        "tot_cnt=0\n",
        "freq=0\n",
        "tot_freq=0\n",
        "\n",
        "for key,value in y_tokenizer.word_counts.items():\n",
        "    tot_cnt=tot_cnt+1\n",
        "    tot_freq=tot_freq+value\n",
        "    if(value<thresh):\n",
        "        cnt=cnt+1\n",
        "        freq=freq+value\n",
        "    \n",
        "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
        "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "% of rare words in vocabulary: 66.34503603813067\n",
            "Total Coverage of rare words: 3.566630093901333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWgQH1XJyzmT",
        "outputId": "2af6c048-6ef1-48f2-b46c-53130d3d4ef5"
      },
      "source": [
        "#prepare a tokenizer for reviews on training data\n",
        "y_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \n",
        "y_tokenizer.fit_on_texts(list(y_tr))\n",
        "\n",
        "#convert text sequences into integer sequences (i.e one hot encode the text in Y)\n",
        "y_tr_seq    =   y_tokenizer.texts_to_sequences(y_tr) \n",
        "y_val_seq   =   y_tokenizer.texts_to_sequences(y_val) \n",
        "\n",
        "#padding zero upto maximum length\n",
        "y_tr    =   pad_sequences(y_tr_seq, maxlen=max_summary_len, padding='post')\n",
        "y_val   =   pad_sequences(y_val_seq, maxlen=max_summary_len, padding='post')\n",
        "\n",
        "#size of vocabulary\n",
        "y_voc  =   y_tokenizer.num_words +1\n",
        "print(\"Size of vocabulary in Y = {}\".format(y_voc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of vocabulary in Y = 11581\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXShzdwXyznb"
      },
      "source": [
        "ind=[]\n",
        "for i in range(len(y_tr)):\n",
        "    cnt=0\n",
        "    for j in y_tr[i]:\n",
        "        if j!=0:\n",
        "            cnt=cnt+1\n",
        "    if(cnt==2):\n",
        "        ind.append(i)\n",
        "\n",
        "y_tr=np.delete(y_tr,ind, axis=0)\n",
        "x_tr=np.delete(x_tr,ind, axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkuFFr2Eyzy_"
      },
      "source": [
        "ind=[]\n",
        "for i in range(len(y_val)):\n",
        "    cnt=0\n",
        "    for j in y_val[i]:\n",
        "        if j!=0:\n",
        "            cnt=cnt+1\n",
        "    if(cnt==2):\n",
        "        ind.append(i)\n",
        "\n",
        "y_val=np.delete(y_val,ind, axis=0)\n",
        "x_val=np.delete(x_val,ind, axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PDN8U-AzUpd"
      },
      "source": [
        "from keras import backend as K \n",
        "import gensim\n",
        "from numpy import *\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "from keras.preprocessing.text import Tokenizer \n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from nltk.corpus import stopwords\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import warnings\n",
        "pd.set_option(\"display.max_colwidth\", 200)\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "print(\"Size of vocabulary from the w2v model = {}\".format(x_voc))\n",
        "\n",
        "K.clear_session()\n",
        "\n",
        "latent_dim = 300\n",
        "embedding_dim=200\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(max_text_len,))\n",
        "\n",
        "#embedding layer\n",
        "enc_emb =  Embedding(x_voc, embedding_dim,trainable=True)(encoder_inputs)\n",
        "\n",
        "#encoder lstm 1\n",
        "encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
        "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
        "\n",
        "#encoder lstm 2\n",
        "encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
        "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
        "\n",
        "#encoder lstm 3\n",
        "encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True,dropout=0.4,recurrent_dropout=0.4)\n",
        "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)\n",
        "\n",
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "\n",
        "#embedding layer\n",
        "dec_emb_layer = Embedding(y_voc, embedding_dim,trainable=True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True,dropout=0.4,recurrent_dropout=0.2)\n",
        "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c])\n",
        "\n",
        "#dense layer\n",
        "decoder_dense =  TimeDistributed(Dense(y_voc, activation='softmax'))\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Define the model \n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzc3FE4LzUq_"
      },
      "source": [
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_xwrzbMyz0e"
      },
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMnbWUnZzQzE"
      },
      "source": [
        "history=model.fit([x_tr,y_tr[:,:-1]], y_tr.reshape(y_tr.shape[0],y_tr.shape[1], 1)[:,1:] ,epochs=50,callbacks=[es],batch_size=128, validation_data=([x_val,y_val[:,:-1]], y_val.reshape(y_val.shape[0],y_val.shape[1], 1)[:,1:]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYaf5RlJzQ0h"
      },
      "source": [
        "from matplotlib import pyplot\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.plot(history.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnwdNLqfzp3s"
      },
      "source": [
        "reverse_target_word_index=y_tokenizer.index_word\n",
        "reverse_source_word_index=x_tokenizer.index_word\n",
        "target_word_index=y_tokenizer.word_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOoP3oeqzteM"
      },
      "source": [
        "# Encode the input sequence to get the feature vector\n",
        "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
        "\n",
        "# Decoder setup\n",
        "# Below tensors will hold the states of the previous time step\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_hidden_state_input = Input(shape=(max_text_len,latent_dim))\n",
        "\n",
        "# Get the embeddings of the decoder sequence\n",
        "dec_emb2= dec_emb_layer(decoder_inputs) \n",
        "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
        "\n",
        "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "decoder_outputs2 = decoder_dense(decoder_outputs2) \n",
        "\n",
        "# Final decoder model\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
        "    [decoder_outputs2] + [state_h2, state_c2])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbBrn3IZzw_e"
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
        "    \n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1,1))\n",
        "    \n",
        "    # Populate the first word of target sequence with the start word.\n",
        "    target_seq[0, 0] = target_word_index['sostok']\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "      \n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
        "        \n",
        "        if(sampled_token!='eostok'):\n",
        "            decoded_sentence += ' '+sampled_token\n",
        "\n",
        "        # Exit condition: either hit max length or find stop word.\n",
        "        if (sampled_token == 'eostok'  or len(decoded_sentence.split()) >= (max_summary_len-1)):\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # Update internal states\n",
        "        e_h, e_c = h, c\n",
        "\n",
        "    return decoded_sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfbZlFHlzzBZ"
      },
      "source": [
        "def seq2summary(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "        if((i!=0 and i!=target_word_index['sostok']) and i!=target_word_index['eostok']):\n",
        "            newString=newString+reverse_target_word_index[i]+' '\n",
        "    return newString\n",
        "\n",
        "def seq2text(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "        if(i!=0):\n",
        "            newString=newString+reverse_source_word_index[i]+' '\n",
        "    return newString"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebT1wOJmz2Pf"
      },
      "source": [
        "for i in range(0,100):\n",
        "    print(\"Review:\",seq2text(x_tr[i]))\n",
        "    print(\"Original summary:\",seq2summary(y_tr[i]))\n",
        "    print(\"Predicted summary:\",decode_sequence(x_tr[i].reshape(1,max_text_len)))\n",
        "    print(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}